{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity score matching\n",
    "\n",
    "A propensity score is the probability that a unit with certain characteristics will be assigned to the treatment group (as opposed to the control group). The scores can be used to **reduce or eliminate selection bias in observational studies by balancing covariates** (the characteristics of participants) between treated and control groups. When the covariates are balanced, it become much easier to match participants with multiple characteristics.\n",
    "\n",
    "Propensity score matching creates sets of participants for treatment and control groups. A matched set consists of at least one participant in the treatment group and one in the control group with similar propensity scores. The goal is to approximate a random experiment, eliminating many of the problems that come with observational data analysis\n",
    "\n",
    "\n",
    "## Basic Steps\n",
    "\n",
    "The basic steps to propensity score matching are:\n",
    "\n",
    "- Collect and prepare the data.\n",
    "\n",
    "- Estimate the propensity scores. The true scores are unknown, but can be estimated by many methods including: discriminant analysis, logistic regression, and random forests. The “best” method is up for debate, but one of the more popular methods is logistic regression.\n",
    "\n",
    "- Match the participants using the estimated scores.\n",
    "\n",
    "- Evaluate the covariates for an even spread across groups. The scores are good estimates for true propensity scores if the matching process successfully distributes covariates over the treated/untreated groups (Ho et. al, 2007)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pymatch.Matcher import Matcher #Match data for an observational study.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('casual inference/data/trainees.csv')\n",
    "control = df[df['trainees']==0]\n",
    "treat = df[df['trainees']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4297.49373433584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control['earnings'].mean()-treat['earnings'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I do a simple comparison in means, we get that the trainees earn less money than those that didn't go through the program. However, if we look at the table above, we notice that trainees are much younger than non trainees, which indicates that **age is probably a confounder**. \n",
    "\n",
    "Let's use matching on age to try to correct that. We will take unit 1 from the treated and pair it with unit 27, since both are 28 years old. Unit 2 we will pair it with unit 34, unit 3 with unit 37, unit 4 we will pair it with unit 35... When it comes to unit 5, we need to find someone with age 29 from the non treated, but that is unit 37, which is already paired. This is not a problem, since **we can use the same unit multiple times. If more than 1 unit is a match, we can choose randomly between them.**\n",
    "\n",
    "This is what the matched dataset looks like for the first 7 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_t_1</th>\n",
       "      <th>trainees_t_1</th>\n",
       "      <th>age</th>\n",
       "      <th>earnings_t_1</th>\n",
       "      <th>unit_t_0</th>\n",
       "      <th>trainees_t_0</th>\n",
       "      <th>earnings_t_0</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>17700</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8800</td>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10200</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>24200</td>\n",
       "      <td>-14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>14400</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_t_1  trainees_t_1  age  earnings_t_1  unit_t_0  trainees_t_0  \\\n",
       "0         1             1   28         17700        27             0   \n",
       "1         2             1   34         10200        34             0   \n",
       "2         3             1   29         14400        37             0   \n",
       "\n",
       "   earnings_t_0   diff  \n",
       "0          8800   8900  \n",
       "1         24200 -14000  \n",
       "2          6200   8200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_on_age=control.drop_duplicates('age')\n",
    "matches=treat.merge(unique_on_age,on='age',how='left',suffixes=(\"_t_1\", \"_t_0\")\n",
    "           ).assign(diff = lambda d: d[\"earnings_t_1\"] - d[\"earnings_t_0\"])\n",
    "matches.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2457.8947368421054"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[\"diff\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create test and control groups and reassign loan_status to be a binary treatment indicator. This is our reponse in the logistic regression model(s) used to generate propensity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this was a very contrived example, just to introduce matching. In reality, we usually have more than one feature and units don't match perfectly. In this case, **we have to define some measurement of proximity to compare how units are close to each other.** \n",
    "\n",
    "One common metric for this is the euclidean norm $||X_i - X_j||$. This difference, however, is not invariant to the scale of the features. This means that features like age, that take values on the tenths, will be much less important when computing this norm compared to features like income, which take the order of hundreds. For this reason, before applying the norm, we need to scale the features so that they are on roughly the same scale.\n",
    "\n",
    "Having defined a distance measure, we can now define the match as the nearest neighbour to that sample we wish to match. \n",
    "\n",
    "To test this estimator, let's consider a medicine example. Once again, we want to find the effect of a medication on days until recovery. Unfortunately, this effect is confounded by severity, sex and age. We have reasons to believe that patients with more severe conditions have a higher chance of receiving the medicine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.049134</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.580323</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.127491</td>\n",
       "      <td>0.486349</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.375033</td>\n",
       "      <td>0.323091</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25.091717</td>\n",
       "      <td>0.209006</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex        age  severity  medication  recovery\n",
       "0    0  35.049134  0.887658           1        31\n",
       "1    1  41.580323  0.899784           1        49\n",
       "2    1  28.127491  0.486349           0        38\n",
       "3    1  36.375033  0.323091           0        35\n",
       "4    0  25.091717  0.209006           0        15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med = pd.read_csv(\"casual inference/data/medicine_impact_recovery.csv\")\n",
    "med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.895799546498726"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med.query(\"medication==1\")[\"recovery\"].mean() - med.query(\"medication==0\")[\"recovery\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at a simple difference in means, $E[Y|T=1]-E[Y|T=0]$, we get that the treatment takes, on average, 16.9 more days to recover than the untreated. This is probably due to confounding, since we don't expect the medicine to cause harm to the patient.\n",
    "\n",
    "To correct for this bias, we will control for features using matching. First, we need to scale our features, otherwise, features like age will have higher importance than features like severity when we compute the distance between points. To do so, we can standardise the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaling = StandardScaler()\n",
    "med[['sex']]=scaling.fit_transform(med[['sex']])\n",
    "med[['age']]=scaling.fit_transform(med[['age']])\n",
    "med[['severity']]=scaling.fit_transform(med[['severity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.049134</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.580323</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.127491</td>\n",
       "      <td>0.486349</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.375033</td>\n",
       "      <td>0.323091</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25.091717</td>\n",
       "      <td>0.209006</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex        age  severity  medication  recovery\n",
       "0    0  35.049134  0.887658           1        31\n",
       "1    1  41.580323  0.899784           1        49\n",
       "2    1  28.127491  0.486349           0        38\n",
       "3    1  36.375033  0.323091           0        35\n",
       "4    0  25.091717  0.209006           0        15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to the matching itself. Instead of coding a matching function, we will use the K nearest neighbour algorithm. This algorithm makes predictions by finding the nearest data point in an estimation or training set.\n",
    "\n",
    "For matching, we will need 2 of those. One, mt0, will store the untreated points and will find matches in the untreated when asked to do so. The other, mt1, will store the treated point and will find matches in the treated when asked to do so. After this fitting step, we can use these KNN models to make predictions, which will be our matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "treat=med[med['medication']==1]\n",
    "control=med[med['medication']==0]\n",
    "X=['sex','age','severity']\n",
    "y=['recovery']\n",
    "knn= KNeighborsRegressor(n_neighbors=1)\n",
    "knn_0= knn.fit(control[X], control[y])\n",
    "knn_1= knn.fit(treat[X], treat[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.049134</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.580323</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex        age  severity  medication  recovery  match\n",
       "0    0  35.049134  0.887658           1        31   31.0\n",
       "1    1  41.580323  0.899784           1        49   49.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find matches for the treatment group looking at the control knn model\n",
    "match_treat=knn_0.predict(treat[X])\n",
    "# find matches for the control looking at the treatment knn model\n",
    "match_control=knn_1.predict(control[X])\n",
    "\n",
    "predicted = pd.concat([treat.assign(match=match_treat),control.assign(match=match_control)])\n",
    "predicted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.02715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((2*predicted[\"medication\"] - 1)*(predicted[\"recovery\"] - predicted[\"match\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sort of matching, we can see that the effect of the medicine is still positive anymore. This means that, controlling for X, the medicine increase the recovery time by about 1 day, on average. This is already a huge improvement on top of the biased estimate that predicted a 16.9 increase in recovery time.\n",
    "\n",
    "However, we can still do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr= LinearRegression()\n",
    "lr_0=lr.fit(control[X], control[y])\n",
    "lr_1=lr.fit(treat[X], treat[y])\n",
    "\n",
    "# find the units that match to the treated\n",
    "treated_match_index = knn_0.kneighbors(treat[X], n_neighbors=1)[1].ravel()\n",
    "# find the units that match to the untreatd\n",
    "control_match_index = knn_1.kneighbors(control[X], n_neighbors=1)[1].ravel() # ravel() change a 2-dimensional array or a multi-dimensional array into a contiguous flattened array. \n",
    "\n",
    "predicted = pd.concat([\n",
    "    (treat\n",
    "     # find the Y match on the other group\n",
    "     .assign(match=knn_0.predict(treat[X])) \n",
    "     \n",
    "     # build the bias correction term\n",
    "     .assign(bias_correct=lr_0.predict(treat[X]) - lr_0.predict(control.iloc[treated_match_index][X]))),\n",
    "    (control\n",
    "     .assign(match=knn_1.predict(control[X]))\n",
    "     .assign(bias_correct=lr_1.predict(control[X]) - lr_0.predict(treat.iloc[control_match_index][X])))\n",
    "])\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, this linear regression that we are fitting doesn't extrapolate on the treatment dimension to get the treatment effect. Instead, its purpose is just to correct bias. Linear regression here is local, in the sense that it doesn't try to see how the treated would be if it looked like the untread. It does none of that extrapolation. This is left to the matching part. The meat of the estimator is still the matching component. The point I want to make here is that OLS is secondary to this estimator.\n",
    "\n",
    "The second point is that matching is a non-parametric estimator. It doesn't assume linearity or any kind of parametric model. As such, it is more flexible than linear regression and can work in situations where linear regression will not, namely, those where non linearity is very strong.\n",
    "\n",
    "With the bias correction formula, I get the following ATE estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((2*predicted[\"medication\"] - 1)*((predicted[\"recovery\"] - predicted[\"match\"])-predicted[\"bias_correct\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct a confidence interval \n",
    "from causalinference import CausalModel\n",
    "cm = CausalModel(\n",
    "    Y=med[\"recovery\"].values, \n",
    "    D=med[\"medication\"].values, \n",
    "    X=med[[\"severity\", \"age\", \"sex\"]].values\n",
    ")\n",
    "\n",
    "cm.est_via_matching(matches=1, bias_adj=True)\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can say with confidence that our medicine does indeed lower the time someone spends at the hospital."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
